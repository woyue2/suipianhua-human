import { NextRequest, NextResponse } from 'next/server';
import {
  handleApiError,
  parseAndValidateBody,
  createSuccessResponse,
} from '@/lib/api-utils';
import { AIReorganizeRequestSchema } from '@/lib/validation';
import { promptManager } from '@/lib/prompts/manager';

/**
 * POST /api/ai/reorganize
 *
 * AI å¤§çº²é‡ç»„æ¥å£
 * æ”¯æŒå¤šä¸ª AI æä¾›å•† (OpenAI, æ™ºè°±AI)
 * æ”¯æŒæç¤ºè¯æ¨¡æ¿é€‰æ‹©å’Œè‡ªå®šä¹‰æç¤ºè¯
 */
export async function POST(req: NextRequest) {
  try {
    // 1. è§£æå¹¶éªŒè¯è¯·æ±‚ä½“
    const body = await parseAndValidateBody(
      req,
      AIReorganizeRequestSchema
    );

    const { content, provider, model, temperature, promptId, customPrompt, customSystemPrompt } = body;

    console.log(`ğŸ“¤ AI Request: provider=${provider}, model=${model}, promptId=${promptId || 'default'}`);

    // 2. è·å–æç¤ºè¯
    let systemPrompt: string;
    let usedTemperature = temperature ?? 0.7;

    if (customSystemPrompt) {
      // ä¼˜å…ˆçº§1ï¼šç”¨æˆ·æä¾›çš„å®Œæ•´è‡ªå®šä¹‰æç¤ºè¯
      systemPrompt = customSystemPrompt;
    } else if (customPrompt) {
      // ä¼˜å…ˆçº§2ï¼šç”¨æˆ·æä¾›çš„æç¤ºè¯ IDï¼Œè·å–å¯¹åº”æ¨¡æ¿
      const template = promptManager.getPrompt(customPrompt);
      if (!template) {
        return NextResponse.json({
          success: false,
          error: 'Prompt not found'
        }, { status: 404 });
      }
      systemPrompt = template.systemPrompt;
      if (template.temperature) {
        usedTemperature = template.temperature;
      }
    } else if (promptId) {
      // ä¼˜å…ˆçº§3ï¼šä½¿ç”¨é¢„è®¾æç¤ºè¯ ID
      const template = promptManager.getPrompt(promptId);
      if (!template) {
        return NextResponse.json({
          success: false,
          error: 'Prompt not found'
        }, { status: 404 });
      }
      systemPrompt = template.systemPrompt;
      if (template.temperature) {
        usedTemperature = template.temperature;
      }
    } else {
      // ä¼˜å…ˆçº§4ï¼šä½¿ç”¨é»˜è®¤æç¤ºè¯
      const defaultPrompt = promptManager.getPrompt('reorganize-default');
      systemPrompt = defaultPrompt?.systemPrompt ?? getDefaultSystemPrompt();
    }

    // 3. è°ƒç”¨ AI API
    let result;

    if (provider === 'zhipu') {
      result = await callZhipuAI(content, model, usedTemperature, systemPrompt);
    } else {
      result = await callOpenAI(content, model, usedTemperature, systemPrompt);
    }

    console.log(`âœ… AI Response received`);

    // 4. è¿”å›ç»“æœ
    return createSuccessResponse({
      reasoning: result.reasoning,
      newStructure: result.newStructure,
      provider,
      model,
      temperature: usedTemperature,
      usedPromptId: promptId ?? (customPrompt ?? 'custom')
    });
  } catch (error: unknown) {
    console.error('âŒ AI Error:', error);
    return handleApiError(error);
  }
}

function getDefaultSystemPrompt(): string {
  return `ä½ æ˜¯ä¸€ä¸ªå¤§çº²æ•´ç†åŠ©æ‰‹ã€‚è¯·å°†ä»¥ä¸‹æ··ä¹±çš„åˆ—è¡¨æ•´ç†æˆå±‚çº§æ¸…æ™°çš„æ ‘çŠ¶ç»“æ„ã€‚

è¦æ±‚ï¼š
1. è¯†åˆ«ä¸»é¢˜ï¼Œåˆ›å»ºçˆ¶çº§åˆ†ç±»
2. å°†ç›¸å…³å†…å®¹å½’çº³åˆ°åˆ†ç±»ä¸‹
3. åªè¿”å› JSON ç»“æ„ï¼Œä¸è¦åŒ…å« ID
4. ä¿æŒåŸæœ‰å†…å®¹ä¸å˜ï¼Œåªè°ƒæ•´å±‚çº§å…³ç³»
5. **é‡è¦ï¼šä¿ç•™æ‰€æœ‰æ ¼å¼æ ‡è®°ï¼** æ–œä½“ç”¨ *text*ï¼Œç²—ä½“ç”¨ **text*

åŸå§‹å†…å®¹ï¼š
{{content}}

è¯·è¿”å›é‡ç»„åçš„ç»“æ„ï¼Œå¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–æ–‡å­—ï¼š
{
  "reasoning": "é‡ç»„çš„ç†ç”±è¯´æ˜",
  "newStructure": {
    "content": "æ ¹èŠ‚ç‚¹å†…å®¹ï¼ˆä¿ç•™æ ¼å¼æ ‡è®°ï¼‰",
    "isHeader": false,
    "isSubHeader": false,
    "tags": [],
    "isItalic": false,
    "children": []
  }
}`;
}

/**
 * è°ƒç”¨æ™ºè°±AI API
 */
async function callZhipuAI(content: string, model: string, temperature: number, systemPrompt: string) {
  const apiKey = process.env.ZHIPU_API_KEY;
  if (!apiKey) {
    throw new Error('ZHIPU_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®');
  }

  const url = 'https://open.bigmodel.cn/api/paas/v4/chat/completions';

  const fullPrompt = `${systemPrompt}

åŸå§‹å†…å®¹ï¼š
${content}

è¯·è¿”å›é‡ç»„åçš„ç»“æ„ï¼Œå¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–æ–‡å­—ï¼š
{
  "reasoning": "é‡ç»„çš„ç†ç”±è¯´æ˜",
  "newStructure": {
    "content": "æ ¹èŠ‚ç‚¹å†…å®¹ï¼ˆä¿ç•™æ ¼å¼æ ‡è®°ï¼‰",
    "isHeader": false,
    "isSubHeader": false,
    "tags": [],
    "isItalic": false,
    "children": [
      {
        "content": "å­èŠ‚ç‚¹å†…å®¹ï¼ˆä¿ç•™æ ¼å¼æ ‡è®°ï¼‰",
        "isHeader": false,
        "isSubHeader": false,
        "tags": [],
        "isItalic": false,
        "children": []
      }
    ]
  }
}`;

  const response = await fetch(url, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${apiKey}`,
    },
    body: JSON.stringify({
      model,
      messages: [
        {
          role: 'user',
          content: fullPrompt,
        },
      ],
      temperature,
      response_format: { type: 'json_object' }, // å¼ºåˆ¶JSONæ ¼å¼
    }),
  });

  if (!response.ok) {
    const errorText = await response.text();
    console.error('âŒ ZhipuAI API Error:', errorText);
    throw new Error(`æ™ºè°±AIè°ƒç”¨å¤±è´¥: ${response.status} ${errorText}`);
  }

  const data = await response.json();
  const responseContent = data.choices[0].message.content;

  // è§£æJSONå“åº”
  try {
    return JSON.parse(responseContent);
  } catch {
    console.error('âŒ JSON Parse Error:', responseContent);
    throw new Error('AIè¿”å›çš„ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼');
  }
}

/**
 * è°ƒç”¨ OpenAI API (ä½¿ç”¨ Vercel AI SDK)
 */
async function callOpenAI(content: string, model: string, temperature: number, systemPrompt: string) {
  const { generateObject } = await import('ai');
  const { createAIModel } = await import('@/lib/ai-config');
  const { ReorganizeResultSchema } = await import('@/lib/ai-schema');

  const aiModel = createAIModel('openai', model);

  const result = await generateObject({
    model: aiModel,
    schema: ReorganizeResultSchema,
    system: systemPrompt,
    prompt: `åŸå§‹å†…å®¹ï¼š
${content}`,
    temperature,
  });

  return result.object;
}
