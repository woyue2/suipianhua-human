
import { NextResponse } from 'next/server';

// Fallback key from test-zhipu.js (for testing purposes)
const DEMO_KEY = '4b210a44e896495d8217066a32fec2b8.xktiqzDDCQDmuRqR';

export async function POST(req: Request) {
  try {
    const { content } = await req.json();

    if (!content) {
      return NextResponse.json(
        { error: 'Content is required' },
        { status: 400 }
      );
    }

    const apiKey = process.env.ZHIPU_API_KEY || DEMO_KEY;
    const url = 'https://open.bigmodel.cn/api/paas/v4/chat/completions';

    const systemPrompt = `ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½æ–‡æ¡£æ•´ç†åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æç”¨æˆ·æä¾›çš„æ–‡æœ¬è¡Œï¼Œè¯†åˆ«æ¯ä¸€è¡Œä¸­åŒ…å«çš„ä¸åŒè¯­ä¹‰éƒ¨åˆ†ï¼Œå¹¶æå‡ºé‡ç»„å»ºè®®ã€‚
    
    ç‰¹åˆ«æ˜¯é’ˆå¯¹å•è¡Œæ–‡æœ¬åŒ…å«å¤šä¸ªä¿¡æ¯ç‚¹çš„æƒ…å†µï¼ˆä¾‹å¦‚ï¼šä»»åŠ¡æè¿° + æ—¶é—´ + æ ‡ç­¾ + è´Ÿè´£äººï¼‰ï¼Œä½ éœ€è¦å°†å®ƒä»¬æ‹†è§£ã€‚
    
    è¯·è¿”å› JSON æ ¼å¼ï¼Œç»“æ„å¦‚ä¸‹ï¼š
    {
      "analysis": [
        {
          "originalLine": "åŸå§‹è¡Œæ–‡æœ¬",
          "segments": [
            { "text": "æå–çš„ç‰‡æ®µ", "type": "ç±»å‹(å¦‚: task, date, tag, person, priority, note)", "confidence": 0.95 }
          ],
          "reorganized": [
             { "content": "é‡ç»„åçš„ä¸»è¦å†…å®¹", "note": "å¤‡æ³¨/æ ‡ç­¾ç­‰å…ƒæ•°æ®" }
          ],
          "action": "å»ºè®®çš„æ“ä½œ (keep | split | extract_metadata)"
        }
      ]
    }
    
    ç¤ºä¾‹è¾“å…¥: "æ˜å¤©ä¸‹åˆ3ç‚¹å¼€ä¼š #å·¥ä½œ @å¼ ä¸‰"
    ç¤ºä¾‹è¾“å‡º: 
    {
      "analysis": [
        {
          "originalLine": "æ˜å¤©ä¸‹åˆ3ç‚¹å¼€ä¼š #å·¥ä½œ @å¼ ä¸‰",
          "segments": [
            { "text": "å¼€ä¼š", "type": "task" },
            { "text": "æ˜å¤©ä¸‹åˆ3ç‚¹", "type": "date" },
            { "text": "#å·¥ä½œ", "type": "tag" },
            { "text": "@å¼ ä¸‰", "type": "person" }
          ],
          "reorganized": [
            { "content": "å¼€ä¼š", "note": "æ—¶é—´: æ˜å¤©ä¸‹åˆ3ç‚¹, æ ‡ç­¾: å·¥ä½œ, è´Ÿè´£äºº: å¼ ä¸‰" }
          ],
          "action": "extract_metadata"
        }
      ]
    }`;

    const payload = {
      model: 'glm-4-flash',
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: content }
      ],
      temperature: 0.1,
      response_format: { type: 'json_object' }
    };

    console.log('ğŸ¤– Calling AI with content length:', content.length);

    const response = await fetch(url, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`,
      },
      body: JSON.stringify(payload),
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error('AI API Error:', errorText);
      return NextResponse.json(
        { error: `AI Provider Error: ${response.status}` },
        { status: response.status }
      );
    }

    const data = await response.json();
    const resultDetails = JSON.parse(data.choices[0].message.content);

    return NextResponse.json(resultDetails);

  } catch (error) {
    console.error('Internal Error:', error);
    return NextResponse.json(
      { error: 'Internal Server Error' },
      { status: 500 }
    );
  }
}
